{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic fluid model with recourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import random\n",
    "import numpy as np\n",
    "from gurobipy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record the optimal draining time under differnet collecting period\n",
    "def opt_tr(range_begin,range_end,model,eps):\n",
    "    t_range = range(range_begin,range_end,2)\n",
    "    opt_st1 = np.zeros(len(range(range_begin,range_end,2)))\n",
    "    for i in range(len(range(range_begin,range_end,2))):\n",
    "        opt_st1[i] = ms_2_update(eps,t_range[i])\n",
    "    return opt_st1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function use to record the heristic model computing performence\n",
    "def running_time_record_heristic(model,eps,t,w1):\n",
    "    #input model name and the tolerence level\n",
    "    start = time.time()\n",
    "    model(eps,w1,t)\n",
    "    end = time.time()\n",
    "    return str(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function use to record the model computing performence(without initialization)\n",
    "def running_time_record_heristic(model,eps,time):\n",
    "    #input model name and the tolerence level\n",
    "    start = time.time()\n",
    "    model(eps,time)\n",
    "    end = time.time()\n",
    "    return str(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function use to plot the bias trade line\n",
    "def plot_diff():\n",
    "    figure3=plt.figure(1)\n",
    "    diff=np.zeros(10)\n",
    "    half_widen=np.zeros(10)\n",
    "    for i in range(0,10):\n",
    "        diff[i]=(result[i]-result[0])/result[0]\n",
    "        half_widen[i]=0.01*i\n",
    "    plt.xlabel(\"half widen difference of random parameter\")\n",
    "    plt.ylabel(\"bias\")\n",
    "    plt.plot(half_widen,diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic fluid model with recourse(without initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now w is unkown and I calculate the draining time under the first stage's decision. if t<t_r, which means all fluid is drain before t_r,\n",
    "#f_1 is used to calculate theta and gradient. if t>t_r, f_2 will be apllied.\n",
    "def ms_without_initialization(eps,time):\n",
    "    t = time\n",
    "    w = np.zeros(scenario)\n",
    "    ms_2 = Model(\"ms_2\")\n",
    "    theta = ms_2.addVar(lb=0,name='theta')\n",
    "    v = ms_2.addVars(K,lb=0,name='v')    \n",
    "\n",
    "    ms_2.addConstrs(((quicksum([np.dot(C[i][j],v[j]) for j in range(K)])) <= 1 for i in range(J)),name='cap')\n",
    "    ms_2.setObjective(theta, GRB.MINIMIZE)\n",
    "    ms_2.update()\n",
    "    ms_2.optimize()\n",
    "    \n",
    "    z_up = 10000000000\n",
    "    z_low = 0\n",
    "    #obj=[]\n",
    "    k=0\n",
    "    while z_up - z_low > eps:\n",
    "\n",
    "        ms_2.optimize()\n",
    "        ms_2.write(\"out.lp\")\n",
    "        obj=[]\n",
    "        # Set objective function\n",
    "        obj.append(ms_2.objVal)\n",
    "        v_0=ms_2.getAttr(\"X\")[1:]\n",
    "        theta_0=ms_2.getAttr(\"X\")[0]\n",
    "        #print(\"v_0\",v_0)\n",
    "        #print(\"theta_0\",theta_0)\n",
    "        \n",
    "        Gradient = np.zeros((scenario,K))\n",
    "        Gradient_average = np.zeros(K)\n",
    "        ms_system = np.zeros(scenario)\n",
    "            \n",
    "            \n",
    "        for s in range(scenario):\n",
    "            \n",
    "            ms_f1 = np.zeros(K)\n",
    "            v_minus_Qalpham = np.zeros(K)\n",
    "            for i in range(K):\n",
    "                v_minus_Qalpham[i] = max(0,np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][i])\n",
    "            #print(v_minus_Qalpham,\"v_minus_Qalpham\")\n",
    "            ms_f1 = np.array(Qam)/ (v_minus_Qalpham+0.001)\n",
    "            ms_system[s] = max(ms_f1[j] for j in range(K))\n",
    "            #print(ms_system,\"ms_system\")\n",
    "            \n",
    "            if ms_system[s]<=t:#use f_1\n",
    "                w[s] = 1\n",
    "                #print(\"f_1 apply\")\n",
    "                #ms_2.addConstrs((v[j] >= max_Qalpham[s]+0.0001 for j in range(K)),name='vk')\n",
    "                Gradient_f1 = np.zeros(K)\n",
    "                max_index = np.argmax(ms_f1)\n",
    "                    #print(\"Qam[max_index]\",np.transpose(np.array([a - b for a, b in zip(v_0, Qalpham)]))[i][max_index]**2)\n",
    "                Gradient[s][max_index] = -Qam[max_index]/np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][max_index]**2\n",
    "                #print(\"Gradient\",Gradient)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            else:#use f_2\n",
    "                #print(\"f_2 apply\")\n",
    "                w[s] = 0\n",
    "                dual = np.zeros(K)\n",
    "                ms_2_f2 = Model(\"ms_2_f2\")\n",
    "                theta_1 = ms_2_f2.addVar(lb=0,name='theta_1')\n",
    "                x = ms_2_f2.addVars(K,lb=0,name='x')\n",
    "                ms_2_f2.addConstrs((x[i] <= (v_0[i]*t)/M[i] for i in range(K)),name='cap_f2')\n",
    "                ms_2_f2.addConstrs((x[i] <= np.transpose(alpha)[s][i]*t + np.transpose(a)[i] + quicksum([np.dot(np.transpose(P)[i][j],x[j]) for j in range(K)]) for i in range(K)),name='remain')\n",
    "                \n",
    "                Qaplphatm=np.matmul(Q,(a+np.transpose(alpha)[s]*t))*M\n",
    "                #print(\"Qaplphatm\",Qaplphatm)\n",
    "                ms_2_f2.addConstrs((theta_1>=(quicksum(Qaplphatm[i]-M[i]*x[i] for i in range(K) if C[j][i]==1))/(1-(sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)))+t for j in range(J)),name='f2_theta')\n",
    "                \n",
    "                ms_2_f2.setObjective(theta_1, GRB.MINIMIZE)\n",
    "                ms_2_f2.update()\n",
    "                ms_2_f2.optimize()\n",
    "                #ms_2_f2.write(\"out.lp\")\n",
    "                #print(\"ms_2_f2\",ms_2_f2.getAttr(\"X\"))\n",
    "                x_0=ms_2_f2.getAttr(\"X\")[1:]\n",
    "                theta_1=ms_2_f2.getAttr(\"X\")[0]\n",
    "                \n",
    "                cons_f2=ms_2_f2.getConstrs()\n",
    "                for i in range(K):                 \n",
    "                    dual[i] = cons_f2[i].getAttr(\"Pi\")*t/M[i]\n",
    "                Gradient[s] = t*dual\n",
    "                #print(dual,\"dual\")\n",
    "                \n",
    "                ms_f2 = np.zeros(J)\n",
    "                for j in range(J):\n",
    "                    ms_f2[j] =  (sum(Qaplphatm[i]-M[i]*x_0[i] for i in range(K) if C[j][i]==1))/(1-sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)) + t\n",
    "                 \n",
    "                ms_system[s] = max(ms_f2[j] for j in range(J))\n",
    "        ms_average = sum(ms_system)/scenario        \n",
    "        #print(\"ms_system\",ms_system)\n",
    "        \n",
    "        z_low = theta_0\n",
    "        if z_up > ms_average:\n",
    "            z_up = ms_average\n",
    "        else:\n",
    "            z_up = z_up\n",
    "        #print(\"z_up\",z_up)\n",
    "        #print(\"z_low\",z_low)\n",
    "        \n",
    "        Gradient_average = np.sum(Gradient,axis=0)/scenario\n",
    "        #print(\"Gradient\",Gradient)\n",
    "        \n",
    "        #print(\"Gradient_average\",Gradient_average)\n",
    "                #print(\"dot\",np.dot(Gradient_average,v_0))  \n",
    "    \n",
    "        ms_2.addConstr((theta>=ms_average-np.dot(Gradient_average,v_0)+quicksum([np.dot(Gradient_average[j],v[j]) for j in range(K)])),name='feasible_cut')\n",
    "        ms_2.update()\n",
    "       \n",
    "    else:\n",
    "        ms_2.optimize()\n",
    "        ms_2.printAttr('X')\n",
    "        print(w,\"w\")\n",
    "    return ms_2.getAttr(\"X\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heristic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario=2\n",
    "K=4\n",
    "J=2\n",
    "alpha1=[0.1,0.3, 0.6,0.9]\n",
    "\n",
    "#alpha1=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "alpha=np.transpose([[i,0.0,0.0,0.0] for i in alpha1])\n",
    "a=np.array([10.0, 10.0, 10.0, 10.0])\n",
    "C=[[1.0,0.0,1.0,0.0],\n",
    "   [0.0,1.0,0.0,1.0]]\n",
    "P=[[0.0,1.0,0.0,0.0],\n",
    "    [0.0,0.0,1.0,0.0],\n",
    "    [0.0,0.0,0.0,1.0],\n",
    "    [0.0,0.0,0.0,0.0]]\n",
    "I=np.eye(K)\n",
    "M=[0.3,0.3,0.5,0.2]\n",
    "Q=np.linalg.inv(I-np.transpose(P))\n",
    "Qalpha=np.matmul(Q,alpha)\n",
    "Qalpham=[Qalpha[i]*M[i] for i in range(K)]\n",
    "max_Qalpham = np.amax(Qalpham, 1)\n",
    "Qa=np.matmul(Q,a)\n",
    "Qam=[Qa[i]*M[i] for i in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_heristic(eps,w1,t):\n",
    "    w=w1\n",
    "    ms_2 = Model(\"ms_2\")\n",
    "    theta = ms_2.addVar(lb=0,name='theta')\n",
    "    v = ms_2.addVars(K,lb=0,name='v')    \n",
    "    for s in range(scenario):\n",
    "        if w[s]==1:\n",
    "            ms_2.addConstrs((v[j] >= np.transpose(Qalpham)[s][j]+0.0001 for j in range(K)),name='vk')\n",
    "    ms_2.addConstrs(((quicksum([np.dot(C[i][j],v[j]) for j in range(K)])) <= 1 for i in range(J)),name='cap')\n",
    "    ms_2.setObjective(theta, GRB.MINIMIZE)\n",
    "    ms_2.update()\n",
    "    ms_2.optimize()\n",
    "    \n",
    "    \n",
    "    z_up = 10000000000\n",
    "    z_low = 0\n",
    "    #obj=[]\n",
    "    k=0\n",
    "    while z_up - z_low > eps:\n",
    "\n",
    "        ms_2.optimize()\n",
    "        ms_2.write(\"out.lp\")\n",
    "        obj=[]\n",
    "        # Set objective function\n",
    "        obj.append(ms_2.objVal)\n",
    "        #n=len(obj)\n",
    "        #print(\"obj\",obj)\n",
    "        v_0=ms_2.getAttr(\"X\")[1:]\n",
    "        theta_0=ms_2.getAttr(\"X\")[0]\n",
    "        #print(\"v_0\",v_0)\n",
    "        #print(\"theta_0\",theta_0)\n",
    "        \n",
    "        Gradient = np.zeros((scenario,K))\n",
    "        Gradient_average = np.zeros(K)\n",
    "        ms_system = np.zeros(scenario)\n",
    "            \n",
    "            \n",
    "        for s in range(scenario):\n",
    "            \n",
    "            ms_f1 = np.zeros(K)\n",
    "            v_minus_Qalpham = np.zeros(K)\n",
    "            for i in range(K):\n",
    "                v_minus_Qalpham[i] = max(0,np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][i])\n",
    "            #print(v_minus_Qalpham,\"v_minus_Qalpham\")\n",
    "            ms_f1 = np.array(Qam)/ (v_minus_Qalpham+0.001)\n",
    "            ms_system[s] = max(ms_f1[j] for j in range(K))\n",
    "            if ms_system[s]<=t:#use f_1\n",
    "                w[s] = 1\n",
    "                #print(\"f_1 apply\")\n",
    "                #ms_2.addConstrs((v[j] >= max_Qalpham[s]+0.0001 for j in range(K)),name='vk')\n",
    "                Gradient_f1 = np.zeros(K)\n",
    "                max_index = np.argmax(ms_f1)\n",
    "                    #print(\"Qam[max_index]\",np.transpose(np.array([a - b for a, b in zip(v_0, Qalpham)]))[i][max_index]**2)\n",
    "                Gradient[s][max_index] = -Qam[max_index]/np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][max_index]**2\n",
    "                #print(\"Gradient\",Gradient)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            else:#use f_2\n",
    "                #print(\"f_2 apply\")\n",
    "                w[s] = 0\n",
    "                dual = np.zeros(K)\n",
    "                ms_2_f2 = Model(\"ms_2_f2\")\n",
    "                theta_1 = ms_2_f2.addVar(lb=0,name='theta_1')\n",
    "                x = ms_2_f2.addVars(K,lb=0,name='x')\n",
    "                ms_2_f2.addConstrs((x[i] <= (v_0[i]*t)/M[i] for i in range(K)),name='cap_f2')\n",
    "                ms_2_f2.addConstrs((x[i] <= np.transpose(alpha)[s][i]*t + np.transpose(a)[i] + quicksum([np.dot(np.transpose(P)[i][j],x[j]) for j in range(K)]) for i in range(K)),name='remain')\n",
    "                \n",
    "                Qaplphatm=np.matmul(Q,(a+np.transpose(alpha)[s]*t))*M\n",
    "                #print(\"Qaplphatm\",Qaplphatm)\n",
    "                ms_2_f2.addConstrs((theta_1>=(quicksum(Qaplphatm[i]-M[i]*x[i] for i in range(K) if C[j][i]==1))/(1-(sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)))+t for j in range(J)),name='f2_theta')\n",
    "                \n",
    "                ms_2_f2.setObjective(theta_1, GRB.MINIMIZE)\n",
    "                ms_2_f2.update()\n",
    "                ms_2_f2.optimize()\n",
    "                #ms_2_f2.write(\"out.lp\")\n",
    "                #print(\"ms_2_f2\",ms_2_f2.getAttr(\"X\"))\n",
    "                x_0=ms_2_f2.getAttr(\"X\")[1:]\n",
    "                theta_1=ms_2_f2.getAttr(\"X\")[0]\n",
    "                \n",
    "                cons_f2=ms_2_f2.getConstrs()\n",
    "                for i in range(K):                 \n",
    "                    dual[i] = cons_f2[i].getAttr(\"Pi\")*t/M[i]\n",
    "                Gradient[s] = t*dual\n",
    "                #print(dual,\"dual\")\n",
    "                \n",
    "                ms_f2 = np.zeros(J)\n",
    "                for j in range(J):\n",
    "                    ms_f2[j] =  (sum(Qaplphatm[i]-M[i]*x_0[i] for i in range(K) if C[j][i]==1))/(1-sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)) + t\n",
    "                 \n",
    "                ms_system[s] = max(ms_f2[j] for j in range(J))\n",
    "        ms_average = sum(ms_system)/scenario        \n",
    "        #print(\"ms_system\",ms_system)\n",
    "        \n",
    "        z_low = theta_0\n",
    "        if z_up > ms_average:\n",
    "            z_up = ms_average\n",
    "        else:\n",
    "            z_up = z_up\n",
    "        #print(\"z_up\",z_up)\n",
    "        #print(\"z_low\",z_low)\n",
    "        \n",
    "        Gradient_average = np.sum(Gradient,axis=0)/scenario\n",
    "        #print(\"Gradient\",Gradient)\n",
    "        \n",
    "        #print(\"Gradient_average\",Gradient_average)\n",
    "                #print(\"dot\",np.dot(Gradient_average,v_0))  \n",
    "    \n",
    "        ms_2.addConstr((theta>=ms_average-np.dot(Gradient_average,v_0)+quicksum([np.dot(Gradient_average[j],v[j]) for j in range(K)])),name='feasible_cut')\n",
    "        ms_2.update()\n",
    "       \n",
    "    else:\n",
    "        ms_2.optimize()\n",
    "        ms_2.printAttr('X')\n",
    "        print(w,\"w\")\n",
    "    return ms_2.getAttr(\"X\")[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deterministic VS random (random alpha, 2 scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario=2\n",
    "K=4\n",
    "J=2    \n",
    "a=np.array([10.0, 10.0, 10.0, 10.0])\n",
    "C=[[1.0,0.0,1.0,0.0],\n",
    "    [0.0,1.0,0.0,1.0]]\n",
    "P=[[0.0,1.0,0.0,0.0],\n",
    "    [0.0,0.0,1.0,0.0],\n",
    "    [0.0,0.0,0.0,1.0],\n",
    "    [0.0,0.0,0.0,0.0]]\n",
    "I=np.eye(K)\n",
    "M = [0.3,0.3,0.5,0.2]\n",
    "\n",
    "Q=np.linalg.inv(I-np.transpose(P))\n",
    "Qa=np.matmul(Q,a)\n",
    "Qam=[Qa[i]*M[i] for i in range(K)]\n",
    "\n",
    "t = 0\n",
    "result=np.zeros(10)\n",
    "for d in range(10):\n",
    "    alpha1 = [0.5-0.01*d,0.5+0.01*d]\n",
    "    alpha=np.transpose([[i,0.0,0.0,0.0] for i in alpha1])\n",
    "    Qalpha=np.matmul(Q,alpha)\n",
    "    Qalpham=[Qalpha[i]*M[i] for i in range(K)]\n",
    "    w = np.zeros(scenario)\n",
    "    ms_2 = Model(\"ms_2\")\n",
    "    theta = ms_2.addVar(lb=0,name='theta')\n",
    "    v = ms_2.addVars(K,lb=0,name='v')    \n",
    "\n",
    "    ms_2.addConstrs(((quicksum([np.dot(C[i][j],v[j]) for j in range(K)])) <= 1 for i in range(J)),name='cap')\n",
    "    ms_2.setObjective(theta, GRB.MINIMIZE)\n",
    "    ms_2.update()\n",
    "    ms_2.optimize()\n",
    "    \n",
    "    z_up = 10000000000\n",
    "    z_low = 0\n",
    "    #obj=[]\n",
    "    k=0\n",
    "    while z_up - z_low > 0.1:\n",
    "\n",
    "        ms_2.optimize()\n",
    "        ms_2.write(\"out.lp\")\n",
    "        obj=[]\n",
    "        # Set objective function\n",
    "        obj.append(ms_2.objVal)\n",
    "        v_0=ms_2.getAttr(\"X\")[1:]\n",
    "        theta_0=ms_2.getAttr(\"X\")[0]\n",
    "        #print(\"v_0\",v_0)\n",
    "        #print(\"theta_0\",theta_0)\n",
    "        \n",
    "        Gradient = np.zeros((scenario,K))\n",
    "        Gradient_average = np.zeros(K)\n",
    "        ms_system = np.zeros(scenario)\n",
    "            \n",
    "            \n",
    "        for s in range(scenario):\n",
    "            \n",
    "            ms_f1 = np.zeros(K)\n",
    "            v_minus_Qalpham = np.zeros(K)\n",
    "            for i in range(K):\n",
    "                v_minus_Qalpham[i] = max(0,np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][i])\n",
    "            #print(v_minus_Qalpham,\"v_minus_Qalpham\")\n",
    "            ms_f1 = np.array(Qam)/ (v_minus_Qalpham+0.001)\n",
    "            ms_system[s] = max(ms_f1[j] for j in range(K))\n",
    "            #print(ms_system,\"ms_system\")\n",
    "            \n",
    "            if ms_system[s]<=t:#use f_1\n",
    "                w[s] = 1\n",
    "                #print(\"f_1 apply\")\n",
    "                #ms_2.addConstrs((v[j] >= max_Qalpham[s]+0.0001 for j in range(K)),name='vk')\n",
    "                Gradient_f1 = np.zeros(K)\n",
    "                max_index = np.argmax(ms_f1)\n",
    "                    #print(\"Qam[max_index]\",np.transpose(np.array([a - b for a, b in zip(v_0, Qalpham)]))[i][max_index]**2)\n",
    "                Gradient[s][max_index] = -Qam[max_index]/np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[s][max_index]**2\n",
    "                #print(\"Gradient\",Gradient)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            else:#use f_2\n",
    "                #print(\"f_2 apply\")\n",
    "                w[s] = 0\n",
    "                dual = np.zeros(K)\n",
    "                ms_2_f2 = Model(\"ms_2_f2\")\n",
    "                theta_1 = ms_2_f2.addVar(lb=0,name='theta_1')\n",
    "                x = ms_2_f2.addVars(K,lb=0,name='x')\n",
    "                ms_2_f2.addConstrs((x[i] <= (v_0[i]*t)/M[i] for i in range(K)),name='cap_f2')\n",
    "                ms_2_f2.addConstrs((x[i] <= np.transpose(alpha)[s][i]*t + np.transpose(a)[i] + quicksum([np.dot(np.transpose(P)[i][j],x[j]) for j in range(K)]) for i in range(K)),name='remain')\n",
    "                \n",
    "                Qaplphatm=np.matmul(Q,(a+np.transpose(alpha)[s]*t))*M\n",
    "                #print(\"Qaplphatm\",Qaplphatm)\n",
    "                ms_2_f2.addConstrs((theta_1>=(quicksum(Qaplphatm[i]-M[i]*x[i] for i in range(K) if C[j][i]==1))/(1-(sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)))+t for j in range(J)),name='f2_theta')\n",
    "                \n",
    "                ms_2_f2.setObjective(theta_1, GRB.MINIMIZE)\n",
    "                ms_2_f2.update()\n",
    "                ms_2_f2.optimize()\n",
    "                #ms_2_f2.write(\"out.lp\")\n",
    "                #print(\"ms_2_f2\",ms_2_f2.getAttr(\"X\"))\n",
    "                x_0=ms_2_f2.getAttr(\"X\")[1:]\n",
    "                theta_1=ms_2_f2.getAttr(\"X\")[0]\n",
    "                \n",
    "                cons_f2=ms_2_f2.getConstrs()\n",
    "                for i in range(K):                 \n",
    "                    dual[i] = cons_f2[i].getAttr(\"Pi\")*t/M[i]\n",
    "                Gradient[s] = t*dual\n",
    "                #print(dual,\"dual\")\n",
    "                \n",
    "                ms_f2 = np.zeros(J)\n",
    "                for j in range(J):\n",
    "                    ms_f2[j] =  (sum(Qaplphatm[i]-M[i]*x_0[i] for i in range(K) if C[j][i]==1))/(1-sum(np.transpose(Qalpham)[s][i] for i in range(K) if C[j][i]==1)) + t\n",
    "                 \n",
    "                ms_system[s] = max(ms_f2[j] for j in range(J))\n",
    "        ms_average = sum(ms_system)/scenario        \n",
    "        #print(\"ms_system\",ms_system)\n",
    "        \n",
    "        z_low = theta_0\n",
    "        if z_up > ms_average:\n",
    "            z_up = ms_average\n",
    "        else:\n",
    "            z_up = z_up\n",
    "        #print(\"z_up\",z_up)\n",
    "        #print(\"z_low\",z_low)\n",
    "        \n",
    "        Gradient_average = np.sum(Gradient,axis=0)/scenario\n",
    "        #print(\"Gradient\",Gradient)\n",
    "        \n",
    "        #print(\"Gradient_average\",Gradient_average)\n",
    "                #print(\"dot\",np.dot(Gradient_average,v_0))  \n",
    "    \n",
    "        ms_2.addConstr((theta>=ms_average-np.dot(Gradient_average,v_0)+quicksum([np.dot(Gradient_average[j],v[j]) for j in range(K)])),name='feasible_cut')\n",
    "        ms_2.update()\n",
    "       \n",
    "    else:\n",
    "        ms_2.optimize()\n",
    "        ms_2.printAttr('X')\n",
    "        #print(w,\"w\")\n",
    "\n",
    "\n",
    "   \n",
    "    result[d]=ms_2.getAttr(\"X\")[0]\n",
    "result\n",
    "plot_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deterministic VS random (random a, 2 scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario=2\n",
    "K=4\n",
    "J=2    \n",
    "t= 20\n",
    "C=[[1.0,0.0,1.0,0.0],\n",
    "    [0.0,1.0,0.0,1.0]]\n",
    "P=[[0.0,1.0,0.0,0.0],\n",
    "    [0.0,0.0,1.0,0.0],\n",
    "    [0.0,0.0,0.0,1.0],\n",
    "    [0.0,0.0,0.0,0.0]]\n",
    "I=np.eye(K)\n",
    "M = [0.3,0.3,0.5,0.2]\n",
    "alpha=np.transpose([0.5,0.0,0.0,0.0])\n",
    "Q=np.linalg.inv(I-np.transpose(P))\n",
    "Qalpha=np.matmul(Q,alpha)\n",
    "Qalpham=Qalpha*M\n",
    "\n",
    "result=np.zeros(10)\n",
    "for d in range(10):\n",
    "    a1 = [10-0.5*d,10+0.5*d]\n",
    "    a = np.transpose([[10,a1[i],10,10] for i in range(2)])\n",
    "    Qa=np.matmul(Q,a)\n",
    "    Qam=[Qa[i]*M[i] for i in range(K)]\n",
    "    w = np.zeros(scenario)\n",
    "    ms_2 = Model(\"ms_2\")\n",
    "    theta = ms_2.addVar(lb=0,name='theta')\n",
    "    v = ms_2.addVars(K,lb=0,name='v')    \n",
    "\n",
    "    ms_2.addConstrs(((quicksum([np.dot(C[i][j],v[j]) for j in range(K)])) <= 1 for i in range(J)),name='cap')\n",
    "    ms_2.setObjective(theta, GRB.MINIMIZE)\n",
    "    ms_2.update()\n",
    "    ms_2.optimize()\n",
    "    \n",
    "    z_up = 10000000000\n",
    "    z_low = 0\n",
    "    #obj=[]\n",
    "    k=0\n",
    "    while z_up - z_low > 0.1:\n",
    "\n",
    "        ms_2.optimize()\n",
    "        ms_2.write(\"out.lp\")\n",
    "        obj=[]\n",
    "        # Set objective function\n",
    "        obj.append(ms_2.objVal)\n",
    "        v_0=ms_2.getAttr(\"X\")[1:]\n",
    "        theta_0=ms_2.getAttr(\"X\")[0]\n",
    "        #print(\"v_0\",v_0)\n",
    "        #print(\"theta_0\",theta_0)\n",
    "        \n",
    "        Gradient = np.zeros((scenario,K))\n",
    "        Gradient_average = np.zeros(K)\n",
    "        ms_system = np.zeros(scenario)\n",
    "            \n",
    "            \n",
    "        for s in range(scenario):\n",
    "            \n",
    "            ms_f1 = np.zeros(K)\n",
    "            v_minus_Qalpham = np.zeros(K)\n",
    "            for i in range(K):\n",
    "                v_minus_Qalpham[i] = max(0,np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[i])\n",
    "            #print(v_minus_Qalpham,\"v_minus_Qalpham\")\n",
    "            ms_f1 = np.transpose(Qam)[s]/ (v_minus_Qalpham+0.001)\n",
    "            #ms[i] =  np.transpose(Qam)[i]/ np.transpose(np.array([a - b for a, b in zip(v_0, Qalpham)]))\n",
    "            ms_system[s] = max(ms_f1[j] for j in range(K))\n",
    "            #print(ms_system,\"ms_system\")\n",
    "            \n",
    "            if ms_system[s]<=t:#use f_1\n",
    "                w[s] = 1\n",
    "                #print(\"f_1 apply\")\n",
    "                #ms_2.addConstrs((v[j] >= max_Qalpham[s]+0.0001 for j in range(K)),name='vk')\n",
    "                Gradient_f1 = np.zeros(K)\n",
    "                max_index = np.argmax(ms_f1)\n",
    "                    #print(\"Qam[max_index]\",np.transpose(np.array([a - b for a, b in zip(v_0, Qalpham)]))[i][max_index]**2)\n",
    "                Gradient[s][max_index] = -np.transpose(Qam)[s][max_index]/np.transpose(np.array([m - n for m, n in zip(v_0, Qalpham)]))[max_index]**2\n",
    "\n",
    "                #print(\"Gradient\",Gradient)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            else:#use f_2\n",
    "                #print(\"f_2 apply\")\n",
    "                w[s] = 0\n",
    "                dual = np.zeros(K)\n",
    "                ms_2_f2 = Model(\"ms_2_f2\")\n",
    "                theta_1 = ms_2_f2.addVar(lb=0,name='theta_1')\n",
    "                x = ms_2_f2.addVars(K,lb=0,name='x')\n",
    "                ms_2_f2.addConstrs((x[i] <= (v_0[i]*t)/M[i] for i in range(K)),name='cap_f2')\n",
    "                ms_2_f2.addConstrs((x[i] <= np.transpose(alpha)[i]*t + np.transpose(a)[s][i] + quicksum([np.dot(np.transpose(P)[i][j],x[j]) for j in range(K)]) for i in range(K)),name='remain')\n",
    "                \n",
    "                Qaplphatm=np.matmul(Q,(np.transpose(a)[0]+alpha*t)*M)\n",
    "                #print(\"Qaplphatm\",Qaplphatm)\n",
    "                ms_2_f2.addConstrs((theta_1>=(quicksum(Qaplphatm[i]-M[i]*x[i] for i in range(K) if C[j][i]==1))/(1-(sum(np.transpose(Qalpham)[i] for i in range(K) if C[j][i]==1)))+t for j in range(J)),name='f2_theta')\n",
    "                \n",
    "                ms_2_f2.setObjective(theta_1, GRB.MINIMIZE)\n",
    "                ms_2_f2.update()\n",
    "                ms_2_f2.optimize()\n",
    "                #ms_2_f2.write(\"out.lp\")\n",
    "                #print(\"ms_2_f2\",ms_2_f2.getAttr(\"X\"))\n",
    "                x_0=ms_2_f2.getAttr(\"X\")[1:]\n",
    "                theta_1=ms_2_f2.getAttr(\"X\")[0]\n",
    "                \n",
    "                cons_f2=ms_2_f2.getConstrs()\n",
    "                for i in range(K):                 \n",
    "                    dual[i] = cons_f2[i].getAttr(\"Pi\")*t/M[i]\n",
    "                Gradient[s] = t*dual\n",
    "                #print(dual,\"dual\")\n",
    "                \n",
    "                ms_f2 = np.zeros(J)\n",
    "                for j in range(J):\n",
    "                    ms_f2[j] =  (sum(Qaplphatm[i]-M[i]*x_0[i] for i in range(K) if C[j][i]==1))/(1-sum(np.transpose(Qalpham)[i] for i in range(K) if C[j][i]==1)) + t\n",
    "                 \n",
    "                ms_system[s] = max(ms_f2[j] for j in range(J))\n",
    "        ms_average = sum(ms_system)/scenario        \n",
    "        #print(\"ms_system\",ms_system)\n",
    "        \n",
    "        z_low = theta_0\n",
    "        if z_up > ms_average:\n",
    "            z_up = ms_average\n",
    "        else:\n",
    "            z_up = z_up\n",
    "        #print(\"z_up\",z_up)\n",
    "        #print(\"z_low\",z_low)\n",
    "        \n",
    "        Gradient_average = np.sum(Gradient,axis=0)/scenario\n",
    "        #print(\"Gradient\",Gradient)\n",
    "        \n",
    "        #print(\"Gradient_average\",Gradient_average)\n",
    "                #print(\"dot\",np.dot(Gradient_average,v_0))  \n",
    "    \n",
    "        ms_2.addConstr((theta>=ms_average-np.dot(Gradient_average,v_0)+quicksum([np.dot(Gradient_average[j],v[j]) for j in range(K)])),name='feasible_cut')\n",
    "        ms_2.update()\n",
    "       \n",
    "    else:\n",
    "        ms_2.optimize()\n",
    "        ms_2.printAttr('X')\n",
    "        #print(w,\"w\")\n",
    "\n",
    "\n",
    "   \n",
    "    result[d]=ms_2.getAttr(\"X\")[0]\n",
    "result\n",
    "plot_diff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
